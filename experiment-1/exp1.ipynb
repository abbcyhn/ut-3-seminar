{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Processor: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz 1.80 GHz\n",
    "* Number of cores: 4\n",
    "* Memory: 16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "* The r/place Parquet dataset - 12GB (22GB uncompressed) - /datas/2022_place_deephaven.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "* Reading in the file, speed comparison\n",
    "* Compute metrics of a column: (mean, std)\n",
    "* Finding the unique value of a column\n",
    "* Cumulative sum of a column\n",
    "* Groupby Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath = '../datas/2022_place_deephaven.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(inputpath)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1. Pandas - Reading exec time: \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jeyhun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:501\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39m@doc\u001b[39m(storage_options\u001b[39m=\u001b[39m_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_parquet\u001b[39m(\n\u001b[0;32m    449\u001b[0m     path: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    455\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    456\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39m    DataFrame\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    503\u001b[0m     \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[0;32m    504\u001b[0m         path,\n\u001b[0;32m    505\u001b[0m         columns\u001b[39m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    509\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jeyhun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:52\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     50\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_parquet(inputpath)\n",
    "print(f\"1. Pandas - Reading exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160353104, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rgb</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01 12:44:10.315000+00:00</td>\n",
       "      <td>4068945</td>\n",
       "      <td>8318294</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>-32768</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01 12:44:22.671000+00:00</td>\n",
       "      <td>4068946</td>\n",
       "      <td>41832</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>-32768</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01 12:44:26.626000+00:00</td>\n",
       "      <td>4068947</td>\n",
       "      <td>3576042</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>-32768</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01 12:44:31.703000+00:00</td>\n",
       "      <td>4068948</td>\n",
       "      <td>13948889</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-32768</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01 12:44:44.409000+00:00</td>\n",
       "      <td>4068949</td>\n",
       "      <td>3576042</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>-32768</td>\n",
       "      <td>-32768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  user_id       rgb   x1   y1     x2     y2\n",
       "0 2022-04-01 12:44:10.315000+00:00  4068945   8318294   42   42 -32768 -32768\n",
       "1 2022-04-01 12:44:22.671000+00:00  4068946     41832  999  999 -32768 -32768\n",
       "2 2022-04-01 12:44:26.626000+00:00  4068947   3576042   44   42 -32768 -32768\n",
       "3 2022-04-01 12:44:31.703000+00:00  4068948  13948889    2    2 -32768 -32768\n",
       "4 2022-04-01 12:44:44.409000+00:00  4068949   3576042   23   23 -32768 -32768"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Pandas - Mean exec time: 0.4100003242492676\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].mean()\n",
    "print(f\"2. Pandas - Mean exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Pandas - Std exec time: 2.5820040702819824\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].std()\n",
    "print(f\"3. Pandas - Std exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Pandas - Unique exec time: 16.425997495651245\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['user_id'].unique()\n",
    "print(f\"4. Pandas - Unique exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Pandas - Cumsum exec time: 1.2599973678588867\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['y1'].cumsum()\n",
    "print(f\"5. Pandas - Cumsum exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Pandas - Groupby Aggregation exec time: 65.74299740791321\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df.groupby('user_id')['x1'].mean()\n",
    "print(f\"6. Pandas - Groupby Aggregation exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray\n",
    "\n",
    "### A low-level framework for parallelizing Python code across processors or clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = ray.data.read_parquet(inputpath)\n",
    "print(f\"1. Ray - Reading exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df.mean('x1')\n",
    "print(f\"2. Ray - Mean exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df.std(\"x1\")\n",
    "print(f\"3. Ray - Std exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df.unique('user_id')\n",
    "print(f\"4. Ray - Unique exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df.cumsum('y1')\n",
    "print(f\"5. Ray - Cumsum exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df.groupby('user_id').mean('x1')\n",
    "print(f\"6. Ray - Groupby Aggregation exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "### A low-level sceduler and a high-level partial Pandas replacement, geared toward running code on compute clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dask - Reading exec time: 0.15599966049194336\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = dd.read_parquet(inputpath)\n",
    "print(f\"1. Dask - Reading exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Dask - Mean exec time: 51.74338912963867\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].mean().compute(scheduler =\"processes\")\n",
    "print(f\"2. Dask - Mean exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Dask - Std exec time: 18.715003967285156\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].std().compute(scheduler =\"processes\")\n",
    "print(f\"3. Dask - Std exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Dask - Unique exec time: 29.739998817443848\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['user_id'].unique().compute(scheduler =\"processes\")\n",
    "print(f\"4. Dask - Unique exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Dask - Cumsum exec time: 28.987157344818115\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_ = df['y1'].cumsum().compute(scheduler =\"processes\")\n",
    "print(f\"5. Dask - Cumsum exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df.groupby('user_id')['x1'].mean().compute(scheduler =\"processes\")\n",
    "print(f\"6. Dask - Groupby Aggregation exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modin\n",
    "\n",
    "### A drop-in replacement for Pandas, powered by either Dask or Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unsupported pandas version: 1.3.4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-37302fea7de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeyhun\\anaconda3\\lib\\site-packages\\modin\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPandasCompatVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mPandasCompatVersion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCURRENT\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPandasCompatVersion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY36\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeyhun\\anaconda3\\lib\\site-packages\\modin\\_compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPandasCompatVersion\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;34m\"\"\"Enum-like class describing if we're working in \"pandas compat\" or normal mode.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeyhun\\anaconda3\\lib\\site-packages\\modin\\_compat\\__init__.py\u001b[0m in \u001b[0;36mPandasCompatVersion\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mCURRENT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLATEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Unsupported pandas version: {pandas.__version__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unsupported pandas version: 1.3.4"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import modin.pandas as pd\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_parquet(inputpath)\n",
    "print(f\"1. Modin - Reading exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].mean()\n",
    "print(f\"2. Modin - Mean exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df['x1'].std()\n",
    "print(f\"3. Modin - Std exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df['user_id'].unique()\n",
    "print(f\"4. Modin - Unique exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df['y1'].cumsum()\n",
    "print(f\"5. Modin - Cumsum exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_ = df.groupby('user_id')['x1'].mean()\n",
    "print(f\"6. Modin - Groupby Aggregation exec time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.plotting._matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7b801022aab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeyhun\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.plotting._matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tests = ['read', 'mean', 'std', 'unique', 'cumsum', 'groupby']\n",
    "results = { 'pandas' : [60 + 46, 0.088, 1.13, 60+17, 1.09, 120 +2],\n",
    "            'dask' : [17, 0.673, 4.33, 29.5, 240+12, 60+22],\n",
    "            'modin' : [3*60+45, 0.526, 5.75, 120+47, 0.276, 480+44],\n",
    "            'vaex': [120+43, 5.72, 5.59, 480+44, 7.26, 6*60 + 48]\n",
    "        } \n",
    "\n",
    "results_df = pd.DataFrame(data=results, index=tests)\n",
    "\n",
    "for test in results_df.index:\n",
    "\tresults_df.loc[test].plot(kind='bar', title=test)\n",
    "\tplt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d8dbdde3823bbf4837fc055306386e5b1eca184e503417258624e0f3dfddda5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
